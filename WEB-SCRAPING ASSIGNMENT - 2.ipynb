{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d24c4faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda3\\lib\\site-packages (4.1.3)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.20.0)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: outcome in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.4.8)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure,socks]~=1.26->selenium) (1.16.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "#Lets first install the selenium library\n",
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba6bad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now import all the required libraries\n",
    "\n",
    "import selenium                     #library that is used to work with selenium\n",
    "import pandas as pd                 #to create dataframe\n",
    "from selenium import webdriver      #importing webdriver module from selenium to open up automated chrome window\n",
    "import warnings                     #to ignore any sort of warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time                         #use to stop search engine for few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cb594af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6435c9",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61ce6a90",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "    1. First get the webpage https://www.naukri.com/\n",
    "    2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "    location” field.\n",
    "    3. Then click the search button.\n",
    "    4. Then scrape the data for the first 10 jobs results you get.\n",
    "    5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f066d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up naukri.com website on automated chrome window\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ab3b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar\n",
    "search_field_designation = driver.find_element_by_class_name(\"suggestor-input \")  #job search bar\n",
    "search_field_designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "016af78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job location\n",
    "search_field_location = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input') #location search bar\n",
    "search_field_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4568dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on search button\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb6a78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "job_titles = []\n",
    "job_locations = []\n",
    "company_names = []\n",
    "job_experiences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3526225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Analyst / Business Analyst',\n",
       " 'Data Analyst / Business Analyst',\n",
       " 'data analyst/ data analytics / Business analyst- SQL/Python/SAS',\n",
       " 'Business analyst + data Analysis',\n",
       " 'Data Analyst',\n",
       " 'Associate Professional Data Analyst',\n",
       " 'Business and Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets extract all the tags having the job-titles\n",
    "titles_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\") #locating web element of title\n",
    "\n",
    "for i in titles_tags:               #iterating over web element of title\n",
    "    title = i.text                  #extracting text from each web element\n",
    "    job_titles.append(title)        #appending each extracted text into empty list\n",
    "job_titles[0:10]                     #printing top 10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "859d15af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets extract all the tags having the job location names\n",
    "locations_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")  #locating web element of location\n",
    "\n",
    "for i in locations_tags:                 #iterating over web element of location name\n",
    "    location = i.text                    #extracting text from each web element\n",
    "    job_locations.append(location)       #appending each extracted text into empty list\n",
    "job_locations[0:10]                      #printing top 10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2366d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['METRO Cash & Carry',\n",
       " 'METRO Cash & Carry',\n",
       " 'Leading US MNC into Analytics',\n",
       " 'Anlage Infotech (I) Pvt. Ltd.',\n",
       " 'upGrad',\n",
       " 'DXC Technology',\n",
       " 'CAREERDOST ENTERPRISE',\n",
       " 'Flipkart',\n",
       " 'Thomson Reuters',\n",
       " 'referral']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets extract all the tags having the company names\n",
    "companies_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")  #locating web element of comapny name\n",
    "\n",
    "for i in companies_tags:                 #iterating over web element of company name\n",
    "    company_name = i.text                #extracting text from each web element\n",
    "    company_names.append(company_name)   #appending each extracted text into empty list\n",
    "company_names[0:10]                       #printing top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a331ce8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-8 Yrs',\n",
       " '3-8 Yrs',\n",
       " '2-7 Yrs',\n",
       " '5-10 Yrs',\n",
       " '1-3 Yrs',\n",
       " '3-6 Yrs',\n",
       " '0-5 Yrs',\n",
       " '3-7 Yrs',\n",
       " '2-4 Yrs',\n",
       " '2-5 Yrs']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets extract all the tags having the experience required data\n",
    "experience_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")  #locating web element of experience required data\n",
    "\n",
    "for i in experience_tags:               #iterating over web element of required job experience        \n",
    "    experience = i.text                 #extracting text from each web element \n",
    "    job_experiences.append(experience)  #appending each extracted text into empty list\n",
    "job_experiences[0:10]                   #printing top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "478009ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst / Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>METRO Cash &amp; Carry</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst / Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>METRO Cash &amp; Carry</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data analyst/ data analytics / Business analys...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi /...</td>\n",
       "      <td>Leading US MNC into Analytics</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business analyst + data Analysis</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "      <td>Anlage Infotech (I) Pvt. Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>upGrad</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Associate Professional Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>DXC Technology</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business and Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CAREERDOST ENTERPRISE</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>referral</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job-title  \\\n",
       "0                    Data Analyst / Business Analyst   \n",
       "1                    Data Analyst / Business Analyst   \n",
       "2  data analyst/ data analytics / Business analys...   \n",
       "3                   Business analyst + data Analysis   \n",
       "4                                       Data Analyst   \n",
       "5                Associate Professional Data Analyst   \n",
       "6                          Business and Data Analyst   \n",
       "7                                Senior Data Analyst   \n",
       "8                                Senior Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                        job-location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi /...   \n",
       "3        Hyderabad/Secunderabad, Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                    company_name experience_required  \n",
       "0             METRO Cash & Carry             3-8 Yrs  \n",
       "1             METRO Cash & Carry             3-8 Yrs  \n",
       "2  Leading US MNC into Analytics             2-7 Yrs  \n",
       "3  Anlage Infotech (I) Pvt. Ltd.            5-10 Yrs  \n",
       "4                         upGrad             1-3 Yrs  \n",
       "5                 DXC Technology             3-6 Yrs  \n",
       "6          CAREERDOST ENTERPRISE             0-5 Yrs  \n",
       "7                       Flipkart             3-7 Yrs  \n",
       "8                Thomson Reuters             2-4 Yrs  \n",
       "9                       referral             2-5 Yrs  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#makig a dataframe\n",
    "\n",
    "jobs = pd.DataFrame({})\n",
    "jobs['job-title'] = job_titles[0:10]\n",
    "jobs[' job-location'] =  job_locations[0:10]\n",
    "jobs['company_name'] = company_names[0:10]\n",
    "jobs['experience_required'] = job_experiences[0:10]\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55a03305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to close automated chrome window\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87ed28d",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e3004cb",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "    1. First get the webpage https://www.naukri.com/\n",
    "    2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "    location” field.\n",
    "    3. Then click the search button.\n",
    "    4. Then scrape the data for the first 10 jobs results you get.\n",
    "    5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0918bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3610671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up naukri.com website on automated chrome window\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ca02722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar\n",
    "search_field_designation = driver.find_element_by_class_name(\"suggestor-input \")  #job search bar\n",
    "search_field_designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0f8b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job location\n",
    "search_field_location = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input') #location search bar\n",
    "search_field_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a407a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on search button\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fccb2d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "job_titles = []\n",
    "job_locations = []\n",
    "company_names = []\n",
    "job_experiences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a456f265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Scientist',\n",
       " 'Sr. Analyst - Applied Data Scientist',\n",
       " 'Applied Data Scientist / ML Senior Engineer (Python / SQL)',\n",
       " 'Data Scientist',\n",
       " 'Expert Data Scientist',\n",
       " 'Principal Data Scientist',\n",
       " 'Analyst - Applied Data Scientist',\n",
       " 'Research Data Scientist',\n",
       " 'Senior Data Scientist Grade12',\n",
       " 'Senior Data Scientist Grade12']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets extract all the tags having the job-titles\n",
    "titles_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\") #locating web element of title\n",
    "\n",
    "for i in titles_tags:               #iterating over web element of title\n",
    "    title = i.text                  #extracting text from each web element\n",
    "    job_titles.append(title)        #appending each extracted text into empty list\n",
    "job_titles[0:10]                     #printing top 10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b5e66d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets extract all the tags having the job location names\n",
    "locations_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")  #locating web element of location\n",
    "\n",
    "for i in locations_tags:                 #iterating over web element of location name\n",
    "    location = i.text                    #extracting text from each web element\n",
    "    job_locations.append(location)       #appending each extracted text into empty list\n",
    "job_locations[0:10]                      #printing top 10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e76db87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UPL',\n",
       " 'Tesco',\n",
       " 'SAP India Pvt.Ltd',\n",
       " 'UPL',\n",
       " 'UPL',\n",
       " 'UPL',\n",
       " 'Tesco',\n",
       " 'Mavenir',\n",
       " 'Flipkart',\n",
       " 'Flipkart']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets extract all the tags having the company names\n",
    "companies_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")  #locating web element of comapny name\n",
    "\n",
    "for i in companies_tags:                 #iterating over web element of company name\n",
    "    company_name = i.text                #extracting text from each web element\n",
    "    company_names.append(company_name)   #appending each extracted text into empty list\n",
    "company_names[0:10]                       #printing top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5211214c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-6 Yrs',\n",
       " '3-5 Yrs',\n",
       " '5-10 Yrs',\n",
       " '1-4 Yrs',\n",
       " '6-9 Yrs',\n",
       " '12-16 Yrs',\n",
       " '1-2 Yrs',\n",
       " '4-9 Yrs',\n",
       " '5-10 Yrs',\n",
       " '5-7 Yrs']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets extract all the tags having the experience required data\n",
    "experience_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")  #locating web element of experience required data\n",
    "\n",
    "for i in experience_tags:               #iterating over web element of required job experience        \n",
    "    experience = i.text                 #extracting text from each web element \n",
    "    job_experiences.append(experience)  #appending each extracted text into empty list\n",
    "job_experiences[0:10]                   #printing top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c63a2266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>UPL</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr. Analyst - Applied Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Applied Data Scientist / ML Senior Engineer (P...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>SAP India Pvt.Ltd</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>UPL</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Expert Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>UPL</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>UPL</td>\n",
       "      <td>12-16 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Analyst - Applied Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Research Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Mavenir</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist Grade12</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist Grade12</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job-title  \\\n",
       "0                              Senior Data Scientist   \n",
       "1               Sr. Analyst - Applied Data Scientist   \n",
       "2  Applied Data Scientist / ML Senior Engineer (P...   \n",
       "3                                     Data Scientist   \n",
       "4                              Expert Data Scientist   \n",
       "5                           Principal Data Scientist   \n",
       "6                   Analyst - Applied Data Scientist   \n",
       "7                            Research Data Scientist   \n",
       "8                      Senior Data Scientist Grade12   \n",
       "9                      Senior Data Scientist Grade12   \n",
       "\n",
       "                              job-location       company_name  \\\n",
       "0  Bangalore/Bengaluru, Mumbai (All Areas)                UPL   \n",
       "1                      Bangalore/Bengaluru              Tesco   \n",
       "2                      Bangalore/Bengaluru  SAP India Pvt.Ltd   \n",
       "3  Bangalore/Bengaluru, Mumbai (All Areas)                UPL   \n",
       "4  Bangalore/Bengaluru, Mumbai (All Areas)                UPL   \n",
       "5  Bangalore/Bengaluru, Mumbai (All Areas)                UPL   \n",
       "6                      Bangalore/Bengaluru              Tesco   \n",
       "7                      Bangalore/Bengaluru            Mavenir   \n",
       "8                      Bangalore/Bengaluru           Flipkart   \n",
       "9                      Bangalore/Bengaluru           Flipkart   \n",
       "\n",
       "  experience_required  \n",
       "0             3-6 Yrs  \n",
       "1             3-5 Yrs  \n",
       "2            5-10 Yrs  \n",
       "3             1-4 Yrs  \n",
       "4             6-9 Yrs  \n",
       "5           12-16 Yrs  \n",
       "6             1-2 Yrs  \n",
       "7             4-9 Yrs  \n",
       "8            5-10 Yrs  \n",
       "9             5-7 Yrs  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#makig a dataframe\n",
    "\n",
    "jobs = pd.DataFrame({})\n",
    "jobs['job-title'] = job_titles[0:10]\n",
    "jobs[' job-location'] =  job_locations[0:10]\n",
    "jobs['company_name'] = company_names[0:10]\n",
    "jobs['experience_required'] = job_experiences[0:10]\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c016ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to close automated chrome window\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24bb236",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ad999a1",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "        \n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25ac7de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a693a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up naukri.com website on automated chrome window\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36e81f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar\n",
    "search_field_designation = driver.find_element_by_class_name(\"suggestor-input \")  #job search bar\n",
    "search_field_designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5d938b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on search button\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e1c7dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying filter on a given location\n",
    "apply_location_filter = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[3]/label/p/span[1]\")\n",
    "apply_location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5aa1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying filter on a given salary\n",
    "apply_salary_filter = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[5]/div[2]/div[2]/label/p/span[1]\")\n",
    "apply_salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f719f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "job_titles = []\n",
    "job_locations = []\n",
    "company_names = []\n",
    "job_experiences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d407997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist - Internet Jobs - II',\n",
       " 'Data Scientist',\n",
       " 'Junior Data Scientist',\n",
       " 'Associate Scientist - Data Engineering',\n",
       " 'Data Scientist || Software Company || Immediate Joiners To max 30 Days',\n",
       " 'Data Scientist (freelance)',\n",
       " 'Data Scientist/ Machine Learning, 2022 Passout Can also apply',\n",
       " 'Data Scientist',\n",
       " 'Associate Data Scientist',\n",
       " 'Hiring For Data Analyst and Data Scientist For Gurgaon Location']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets extract all the tags having the job-titles\n",
    "titles_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\") #locating web element of title\n",
    "\n",
    "for i in titles_tags:               #iterating over web element of title\n",
    "    title = i.text                  #extracting text from each web element\n",
    "    job_titles.append(title)        #appending each extracted text into empty list\n",
    "job_titles[0:10]                     #printing top 10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a97b35a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Noida, Bangalore/Bengaluru',\n",
       " 'Noida',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'New Delhi, Delhi',\n",
       " 'Hyderabad/Secunderabad, Pune, Chennai, Delhi / NCR, Vadodara, Mumbai (All Areas)',\n",
       " 'Gurgaon, Bengaluru',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Noida, Gurgaon/Gurugram, Delhi / NCR']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets extract all the tags having the job location names\n",
    "locations_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")  #locating web element of location\n",
    "\n",
    "for i in locations_tags:                 #iterating over web element of location name\n",
    "    location = i.text                    #extracting text from each web element\n",
    "    job_locations.append(location)       #appending each extracted text into empty list\n",
    "job_locations[0:10]                      #printing top 10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9e49a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jobs Territory',\n",
       " 'Ashkom Media India Private Limited',\n",
       " 'EASY DATA ANALYTICS TECHNOLOGY PRIVATE LIMITED',\n",
       " 'AXA Technology Services India Pvt. Ltd',\n",
       " 'Skyleaf Consultants',\n",
       " '2Coms',\n",
       " 'Creative Hands HR Consultancy',\n",
       " 'BlackBuck',\n",
       " 'Optum',\n",
       " 'Shadow Placements']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets extract all the tags having the company names\n",
    "companies_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")  #locating web element of comapny name\n",
    "\n",
    "for i in companies_tags:                 #iterating over web element of company name\n",
    "    company_name = i.text                #extracting text from each web element\n",
    "    company_names.append(company_name)   #appending each extracted text into empty list\n",
    "company_names[0:10]                       #printing top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f15c183b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-6 Yrs',\n",
       " '3-6 Yrs',\n",
       " '1-2 Yrs',\n",
       " '2-5 Yrs',\n",
       " '3-8 Yrs',\n",
       " '2-7 Yrs',\n",
       " '0-4 Yrs',\n",
       " '3-7 Yrs',\n",
       " '1-5 Yrs',\n",
       " '3-7 Yrs']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets extract all the tags having the experience required data\n",
    "experience_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")  #locating web element of experience required data\n",
    "\n",
    "for i in experience_tags:               #iterating over web element of required job experience        \n",
    "    experience = i.text                 #extracting text from each web element \n",
    "    job_experiences.append(experience)  #appending each extracted text into empty list\n",
    "job_experiences[0:10]                   #printing top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac4ffb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Internet Jobs - II</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>Jobs Territory</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>EASY DATA ANALYTICS TECHNOLOGY PRIVATE LIMITED</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associate Scientist - Data Engineering</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AXA Technology Services India Pvt. Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist || Software Company || Immediat...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Skyleaf Consultants</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist (freelance)</td>\n",
       "      <td>New Delhi, Delhi</td>\n",
       "      <td>2Coms</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist/ Machine Learning, 2022 Passout...</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Delhi /...</td>\n",
       "      <td>Creative Hands HR Consultancy</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon, Bengaluru</td>\n",
       "      <td>BlackBuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For Data Analyst and Data Scientist For...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Shadow Placements</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job-title  \\\n",
       "0                Data Scientist - Internet Jobs - II   \n",
       "1                                     Data Scientist   \n",
       "2                              Junior Data Scientist   \n",
       "3             Associate Scientist - Data Engineering   \n",
       "4  Data Scientist || Software Company || Immediat...   \n",
       "5                         Data Scientist (freelance)   \n",
       "6  Data Scientist/ Machine Learning, 2022 Passout...   \n",
       "7                                     Data Scientist   \n",
       "8                           Associate Data Scientist   \n",
       "9  Hiring For Data Analyst and Data Scientist For...   \n",
       "\n",
       "                                        job-location  \\\n",
       "0  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "1                         Noida, Bangalore/Bengaluru   \n",
       "2                                              Noida   \n",
       "3                                   Gurgaon/Gurugram   \n",
       "4              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "5                                   New Delhi, Delhi   \n",
       "6  Hyderabad/Secunderabad, Pune, Chennai, Delhi /...   \n",
       "7                                 Gurgaon, Bengaluru   \n",
       "8                                   Gurgaon/Gurugram   \n",
       "9               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "\n",
       "                                     company_name experience_required  \n",
       "0                                  Jobs Territory             3-6 Yrs  \n",
       "1              Ashkom Media India Private Limited             3-6 Yrs  \n",
       "2  EASY DATA ANALYTICS TECHNOLOGY PRIVATE LIMITED             1-2 Yrs  \n",
       "3          AXA Technology Services India Pvt. Ltd             2-5 Yrs  \n",
       "4                             Skyleaf Consultants             3-8 Yrs  \n",
       "5                                           2Coms             2-7 Yrs  \n",
       "6                   Creative Hands HR Consultancy             0-4 Yrs  \n",
       "7                                       BlackBuck             3-7 Yrs  \n",
       "8                                           Optum             1-5 Yrs  \n",
       "9                               Shadow Placements             3-7 Yrs  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#makig a dataframe\n",
    "\n",
    "jobs = pd.DataFrame({})\n",
    "jobs['job-title'] = job_titles[0:10]\n",
    "jobs[' job-location'] =  job_locations[0:10]\n",
    "jobs['company_name'] = company_names[0:10]\n",
    "jobs['experience_required'] = job_experiences[0:10]\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c79c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to close automated chrome window\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de0d543",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc27e9d4",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "    1. Brand\n",
    "    2. Product Description\n",
    "    3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "    1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "    2. Enter “sunglasses” in the search field where “search for products, brands andmore” is written and\n",
    "    click the search icon\n",
    "    3. After that you will reach to the page having a lot of sunglasses. From this pageyou can scrap the\n",
    "    required data as usual.\n",
    "    4. After scraping data from the first page, go to the “Next” Button at the bottom ofthe page , then\n",
    "    click on it.\n",
    "    5. Now scrape data from this page as usual\n",
    "    6. Repeat this until you get data for 100 sunglasses.\n",
    "Note: That all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7b27225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c972c793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up flipkart.com website on automated chrome window\n",
    "driver.get(' https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c7b35c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for product search bar\n",
    "search_field_product = driver.find_element_by_class_name(\"_3704LK\")  #product search bar\n",
    "search_field_product.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a89a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on search button\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b188c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list\n",
    "brand_name_list = [] \n",
    "product_desc_list = []\n",
    "price_list = []\n",
    "discount_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4fe86341",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3):    #running for loop with range to run this loop 3 times\n",
    "    \n",
    "    brand_name_tags = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\") #locating web element of brand name\n",
    "    for i in brand_name_tags:               #iterating over web element of brand name\n",
    "        brand_name = i.text                  #fetching text from the web element\n",
    "        brand_name_list.append(brand_name)        #appending data(text) into the empty list\n",
    "        \n",
    "    product_desc_tags = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\") #locating web element of product description\n",
    "    for i in product_desc_tags:               #iterating over web element of product description\n",
    "        product_desc = i.text                  #fetching text from the web element\n",
    "        product_desc_list.append(product_desc)        #appending data(text) into the empty list\n",
    "        \n",
    "    price_tags = driver.find_elements_by_xpath(\"//a[@class='_3bPFwb']/div[1]/div[1]\") #locating web element of product price\n",
    "    for i in price_tags:               #iterating over web element of product price\n",
    "        price = i.text                  #fetching text from the web element\n",
    "        price_list.append(price)        #appending data(text) into the empty list\n",
    "        \n",
    "    discount_tags = driver.find_elements_by_xpath(\"//a[@class='_3bPFwb']/div[1]/div[3]\") #locating web element of product discount\n",
    "    for i in discount_tags:               #iterating over web element of product discount\n",
    "        discount = i.text                  #fetching text from the web element\n",
    "        discount_list.append(discount)        #appending data(text) into the empty list    \n",
    "    \n",
    "    next_button = driver.find_element_by_class_name(\"_1LKTO3\")\n",
    "    next_button.click()            #locating web element of next button and then clicking on next button\n",
    "    \n",
    "    time.sleep(5)                  #using time to pause the search engine for 5 sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f875e91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Riding Glasses, UV Protection Clubmaster, Wayf...</td>\n",
       "      <td>₹329</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>₹630</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹647</td>\n",
       "      <td>28% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (...</td>\n",
       "      <td>₹283</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹729</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Mi</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹764</td>\n",
       "      <td>23% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection, Gradient Cat-eye, Wayfarer Sung...</td>\n",
       "      <td>₹575</td>\n",
       "      <td>28% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹264</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Riding Glasses Rectangular, Way...</td>\n",
       "      <td>₹695</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand Name                                Product Description Price  \\\n",
       "0    Singco India  Riding Glasses, UV Protection Clubmaster, Wayf...  ₹329   \n",
       "1    Singco India  Gradient, Toughened Glass Lens, UV Protection ...  ₹630   \n",
       "2        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹647   \n",
       "3          SUNBEE  UV Protection, Polarized Wayfarer Sunglasses (...  ₹283   \n",
       "4        Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹639   \n",
       "..            ...                                                ...   ...   \n",
       "95  VINCENT CHASE  Gradient, UV Protection Wayfarer Sunglasses (F...  ₹729   \n",
       "96             Mi         UV Protection Round Sunglasses (Free Size)  ₹764   \n",
       "97       Fastrack  UV Protection, Gradient Cat-eye, Wayfarer Sung...  ₹575   \n",
       "98      New Specs      UV Protection Wayfarer Sunglasses (Free Size)  ₹264   \n",
       "99         AISLIN  UV Protection, Riding Glasses Rectangular, Way...  ₹695   \n",
       "\n",
       "   Discount  \n",
       "0   83% off  \n",
       "1   78% off  \n",
       "2   28% off  \n",
       "3   78% off  \n",
       "4   20% off  \n",
       "..      ...  \n",
       "95  70% off  \n",
       "96  23% off  \n",
       "97  28% off  \n",
       "98  79% off  \n",
       "99  78% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#makig a dataframe\n",
    "\n",
    "product_details = pd.DataFrame({})\n",
    "product_details['Brand Name'] = brand_name_list[0:100]\n",
    "product_details['Product Description'] =  product_desc_list[0:100]\n",
    "product_details['Price'] = price_list[0:100]\n",
    "product_details['Discount'] = discount_list[0:100]\n",
    "\n",
    "product_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "993e001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to close automated chrome window\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009c2c74",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ab9c11b",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "\n",
    "When you will open the above link you will reach to the below shown webpage .\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "    1. Rating\n",
    "    2. Review summary\n",
    "    3. Full review\n",
    "    4. You have to scrape this data for first 100 reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c1894c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f98d684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up given website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c382bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on all reviews button so that we can scrap all the data together\n",
    "all_review_button = driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div/div/div[5]/div/a/div\")\n",
    "all_review_button.click()            #locating web element of all reviews button and then clicking on that button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ac13006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list\n",
    "ratings_list = [] \n",
    "review_summary_list = []\n",
    "full_review_list = []          \n",
    "\n",
    "\n",
    "for i in range(0,10):    #running for loop with range to run this loop 9 times\n",
    "    \n",
    "    rating_tags = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\") #locating web element of ratings\n",
    "    for i in rating_tags:               #iterating over web element of rating\n",
    "        ratings = i.text                  #extracting text from each web element\n",
    "        ratings_list.append(ratings)        #appending each extracted text into empty list\n",
    "        \n",
    "    review_summary_tags = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\") #locating web element of review summary\n",
    "    for i in review_summary_tags:               #iterating over web element of review summary\n",
    "        review_summary = i.text                  #fetching text from the web element\n",
    "        review_summary_list.append(review_summary)        #appending data(text) into the empty list\n",
    "        \n",
    "    full_review_tags = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\") #locating web element of full review\n",
    "    for i in full_review_tags:               #iterating over web element of full review\n",
    "        full_review = i.text                  #fetching text from the web element\n",
    "        full_review_list.append(full_review)        #appending data(text) into the empty list\n",
    "        \n",
    "    next_button = driver.find_element_by_class_name(\"_1LKTO3\")\n",
    "    next_button.click()            #locating web element of next button and then clicking on next button\n",
    "    \n",
    "    time.sleep(5)                  #using time to pause the search engine for 5 sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0383c52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Iphone is just awesome.. battery backup is ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Excellent camera, good performance, no lag. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Totally in love with this ❤ the camera quality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Really worth of money. i just love it. It is t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings       Review Summary  \\\n",
       "0        5            Brilliant   \n",
       "1        5       Simply awesome   \n",
       "2        5  Best in the market!   \n",
       "3        5     Perfect product!   \n",
       "4        5            Fabulous!   \n",
       "..     ...                  ...   \n",
       "95       5     Perfect product!   \n",
       "96       5    Worth every penny   \n",
       "97       5       Simply awesome   \n",
       "98       5       Classy product   \n",
       "99       5             Terrific   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  Iphone is just awesome.. battery backup is ver...  \n",
       "96  Best budget Iphone till date ❤️ go for it guys...  \n",
       "97  Excellent camera, good performance, no lag. Th...  \n",
       "98  Totally in love with this ❤ the camera quality...  \n",
       "99  Really worth of money. i just love it. It is t...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#makig a dataframe\n",
    "\n",
    "data = pd.DataFrame({})\n",
    "data['Ratings'] = ratings_list[0:100]\n",
    "data['Review Summary'] =  review_summary_list[0:100]\n",
    "data['Full Review'] = full_review_list[0:100]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "68bf3b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to close automated chrome window\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32f2470",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "raw",
   "id": "899b766e",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "    1. Brand\n",
    "    2. Product Description\n",
    "    3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0e2969fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43ea1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up flipkart.com website on automated chrome window\n",
    "driver.get(' https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6915769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for product search bar\n",
    "search_field_product = driver.find_element_by_class_name(\"_3704LK\")  #product search bar\n",
    "search_field_product.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c46d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on search button\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "819cade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list\n",
    "brand_name_list = [] \n",
    "product_desc_list = []\n",
    "price_list = []\n",
    "discount_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3422d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3):    #running for loop with range to run this loop 3 times\n",
    "    \n",
    "    brand_name_tags = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\") #locating web element of brand name\n",
    "    for i in brand_name_tags:               #iterating over web element of brand name\n",
    "        brand_name = i.text                  #fetching text from the web element\n",
    "        brand_name_list.append(brand_name)        #appending data(text) into the empty list\n",
    "        \n",
    "    product_desc_tags = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\") #locating web element of product description\n",
    "    for i in product_desc_tags:               #iterating over web element of product description\n",
    "        product_desc = i.text                  #fetching text from the web element\n",
    "        product_desc_list.append(product_desc)        #appending data(text) into the empty list\n",
    "        \n",
    "    price_tags = driver.find_elements_by_xpath(\"//a[@class='_3bPFwb']/div[1]/div[1]\") #locating web element of product price\n",
    "    for i in price_tags:               #iterating over web element of product price\n",
    "        price = i.text                  #fetching text from the web element\n",
    "        price_list.append(price)        #appending data(text) into the empty list\n",
    "        \n",
    "    discount_tags = driver.find_elements_by_xpath(\"//a[@class='_3bPFwb']/div[1]/div[3]\") #locating web element of product discount\n",
    "    for i in discount_tags:               #iterating over web element of product discount\n",
    "        discount = i.text                  #fetching text from the web element\n",
    "        discount_list.append(discount)        #appending data(text) into the empty list    \n",
    "    \n",
    "    next_button = driver.find_element_by_class_name(\"_1LKTO3\")\n",
    "    next_button.click()            #locating web element of next button and then clicking on next button\n",
    "    \n",
    "    time.sleep(5)                  #using time to pause the search engine for 5 sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d320f980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹158</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹245</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Stylish Comfortable Lightweight, Breathable Wa...</td>\n",
       "      <td>₹692</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹269</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>STYLISH MENS BLACK SNEAKER Sneakers For Men</td>\n",
       "      <td>₹351</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SCATCHITE</td>\n",
       "      <td>5011-Latest Collection Stylish &amp; Trendy Casual...</td>\n",
       "      <td>₹348</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>516 Trendy Star Perfect Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 2 Casual Shoes For Men Sneakers ...</td>\n",
       "      <td>₹219</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ONECENTRE</td>\n",
       "      <td>Combo Pack of 3 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹250</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>CLYMB</td>\n",
       "      <td>Ebernon Low Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand Name                                Product Description  \\\n",
       "0                URBANBOX      Modern Trendy Sneakers Shoes Sneakers For Men   \n",
       "1                  BRUTON                                   Sneakers For Men   \n",
       "2   HRX by Hrithik Roshan  Stylish Comfortable Lightweight, Breathable Wa...   \n",
       "3                   BIRDE                                   Sneakers For Men   \n",
       "4                Magnolia        STYLISH MENS BLACK SNEAKER Sneakers For Men   \n",
       "..                    ...                                                ...   \n",
       "95              SCATCHITE  5011-Latest Collection Stylish & Trendy Casual...   \n",
       "96               ASTEROID           516 Trendy Star Perfect Sneakers For Men   \n",
       "97                 Chevit  Combo Pack of 2 Casual Shoes For Men Sneakers ...   \n",
       "98              ONECENTRE      Combo Pack of 3 Casual Shoes Sneakers For Men   \n",
       "99                  CLYMB                       Ebernon Low Sneakers For Men   \n",
       "\n",
       "   Price Discount  \n",
       "0   ₹158  84% off  \n",
       "1   ₹245  81% off  \n",
       "2   ₹692  80% off  \n",
       "3   ₹269  73% off  \n",
       "4   ₹351  64% off  \n",
       "..   ...      ...  \n",
       "95  ₹348  65% off  \n",
       "96  ₹449  77% off  \n",
       "97  ₹219  78% off  \n",
       "98  ₹250  60% off  \n",
       "99  ₹599  60% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#makig a dataframe\n",
    "\n",
    "product_details = pd.DataFrame({})\n",
    "product_details['Brand Name'] = brand_name_list[0:100]\n",
    "product_details['Product Description'] =  product_desc_list[0:100]\n",
    "product_details['Price'] = price_list[0:100]\n",
    "product_details['Discount'] = discount_list[0:100]\n",
    "\n",
    "product_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b5c1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to close automated chrome window\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de8b08c",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c599906f",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, as shown inthe below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image.\n",
    "Note: Applying the filter and scraping the data, everything should be done through code only and there\n",
    "should not be any manual step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5ea50457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5131808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up myntra.com website on automated chrome window\n",
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "188f0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying filter on a given colour\n",
    "apply_colour_filter = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label\")\n",
    "apply_colour_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "281a3711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying filter on a given price\n",
    "apply_price_filter = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label\")\n",
    "apply_price_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1dae2fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list\n",
    "brand_name_list = [] \n",
    "short_desc_list = []\n",
    "price_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ed7b46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2):    #running for loop with range to run this loop 2 times\n",
    "    \n",
    "    brand_name_tags = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\") #locating web element of brand name\n",
    "    for i in brand_name_tags:               #iterating over web element of brand name\n",
    "        brand_name = i.text                  #fetching text from the web element\n",
    "        brand_name_list.append(brand_name)        #appending data(text) into the empty list\n",
    "        \n",
    "    short_desc_tags = driver.find_elements_by_xpath(\"//h4[@class='product-product']\") #locating web element of short shoe description\n",
    "    for i in short_desc_tags:               #iterating over web element of short shoe description\n",
    "        short_desc = i.text                  #fetching text from the web element\n",
    "        short_desc_list.append(short_desc)        #appending data(text) into the empty list\n",
    "        \n",
    "    price_tags = driver.find_elements_by_xpath(\"//div[@class='product-price']/span\") #locating web element of shoe price\n",
    "    for i in price_tags:               #iterating over web element of shoe price\n",
    "        price = i.text                  #fetching text from the web element\n",
    "        price_list.append(price)        #appending data(text) into the empty list\n",
    "        \n",
    "   \n",
    "    next_button = driver.find_element_by_class_name(\"pagination-next\")\n",
    "    next_button.click()            #locating web element of next button and then clicking on next button\n",
    "    \n",
    "    time.sleep(5)                  #using time to pause the search engine for 5 sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cc7e0556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Shoe Short Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "      <td>Rs. 7199Rs. 8999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Miler2 Running Shoes</td>\n",
       "      <td>Rs. 11495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Charged Rouge 3 Run Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women React MR 3 Running Shoes</td>\n",
       "      <td>Rs. 8920Rs. 10495(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Women Textured Mules</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "      <td>Rs. 7490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Block Pumps with Bows</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Leather Loafers</td>\n",
       "      <td>Rs. 11899Rs. 16999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Wedge Sandals</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand Name          Shoe Short Description                        Price\n",
       "0       Skechers      Men Max Cushioning Running    Rs. 7199Rs. 8999(20% OFF)\n",
       "1           ALDO                    Men Sneakers                     Rs. 9999\n",
       "2           Nike  Men React Miler2 Running Shoes                    Rs. 11495\n",
       "3   UNDER ARMOUR   Men Charged Rouge 3 Run Shoes                     Rs. 7999\n",
       "4           Nike  Women React MR 3 Running Shoes   Rs. 8920Rs. 10495(15% OFF)\n",
       "..           ...                             ...                          ...\n",
       "95       Bugatti            Women Textured Mules                     Rs. 7999\n",
       "96     J.FONTINI      Men Leather Formal Loafers                     Rs. 7490\n",
       "97          ALDO           Block Pumps with Bows                     Rs. 8999\n",
       "98     Cole Haan           Women Leather Loafers  Rs. 11899Rs. 16999(30% OFF)\n",
       "99          ALDO                   Wedge Sandals                     Rs. 7999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#makig a dataframe\n",
    "\n",
    "product_details = pd.DataFrame({})\n",
    "product_details['Brand Name'] = brand_name_list[0:100]\n",
    "product_details['Shoe Short Description'] =  short_desc_list[0:100]\n",
    "product_details['Price'] = price_list[0:100]\n",
    "\n",
    "product_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d3a22f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to close automated chrome window\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124379ad",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1722402",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "    1. Title\n",
    "    2. Ratings\n",
    "    3. Price\n",
    "As shown in the below image as the tick marked attributes.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6cfc1de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6fbbac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up amazon.in website on automated chrome window\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "589ce6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for product search bar\n",
    "search_field_product = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")  #product search bar\n",
    "search_field_product.send_keys(\"laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4c29815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on search button\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "158ac5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying filter on a given cpu type filter - Intel Core i7\n",
    "apply_cpu_type_filter = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[4]/li[13]/span/a/div\")\n",
    "apply_cpu_type_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae08765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying filter on a given cpu type filter- Intel Core i9 \n",
    "apply_cpu_type_filter = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/ul[4]/li[14]/span/a/div\")\n",
    "apply_cpu_type_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "256a09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list\n",
    "title_list = [] \n",
    "ratings_list = []\n",
    "price_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aaca7a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets extract all the tags having the title, ratings and price\n",
    "title_tags = driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\") #locating web element of title\n",
    "for i in title_tags:               #iterating over web element of title\n",
    "    title = i.text                  #fetching text from the web element\n",
    "    title_list.append(title)        #appending data(text) into the empty list\n",
    "        \n",
    "ratings_tags = driver.find_elements_by_xpath(\"//span[@class='a-icon-alt']\") #locating web element of ratings\n",
    "for i in ratings_tags:               #iterating over web element of ratings\n",
    "    ratings = i.text                  #fetching text from the web element\n",
    "    ratings_list.append(ratings)        #appending data(text) into the empty list\n",
    "        \n",
    "price_tags = driver.find_elements_by_xpath(\"//span[@class='a-price']\") #locating web element of price\n",
    "for i in price_tags:               #iterating over web element of price\n",
    "    price = i.text                  #fetching text from the web element\n",
    "    price_list.append(price)        #appending data(text) into the empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5e843beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mi Notebook Ultra 3.2K Resolution Display Inte...</td>\n",
       "      <td></td>\n",
       "      <td>₹77,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td></td>\n",
       "      <td>₹57,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td></td>\n",
       "      <td>₹86,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td></td>\n",
       "      <td>₹89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td></td>\n",
       "      <td>₹85,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td></td>\n",
       "      <td>₹79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...</td>\n",
       "      <td></td>\n",
       "      <td>₹86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LG Gram 16 inches Intel Evo 11th Gen Core i7 U...</td>\n",
       "      <td></td>\n",
       "      <td>₹1,01,112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LG Gram Intel Evo 11th Gen Core i7 17 inches U...</td>\n",
       "      <td></td>\n",
       "      <td>₹93,799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021) 15.6-inch (39.62 cm...</td>\n",
       "      <td></td>\n",
       "      <td>₹92,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings      Price\n",
       "0  Mi Notebook Ultra 3.2K Resolution Display Inte...            ₹77,999\n",
       "1  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...            ₹57,490\n",
       "2  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....            ₹86,900\n",
       "3  ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...            ₹89,990\n",
       "4  HP Pavilion x360 11th Gen Intel Core i7 14 inc...            ₹85,890\n",
       "5  Samsung Galaxy Book2 Intel 12th Gen core i7 39...            ₹79,990\n",
       "6  HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...            ₹86,990\n",
       "7  LG Gram 16 inches Intel Evo 11th Gen Core i7 U...          ₹1,01,112\n",
       "8  LG Gram Intel Evo 11th Gen Core i7 17 inches U...            ₹93,799\n",
       "9  ASUS TUF Gaming F15 (2021) 15.6-inch (39.62 cm...            ₹92,990"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#makig a dataframe\n",
    "\n",
    "laptop_details = pd.DataFrame({})\n",
    "laptop_details['Title'] = title_list[0:10]\n",
    "laptop_details['Ratings'] =  ratings_list[0:10]\n",
    "laptop_details['Price'] = price_list[0:10]\n",
    "\n",
    "laptop_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f7b9e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to close automated chrome window\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd3039a",
   "metadata": {},
   "source": [
    "# Q9"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a796a790",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "    1. First get the webpage https://www.ambitionbox.com/\n",
    "    2. Click on the Job option as shown in the image\n",
    "    3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "    “Data Scientist” and click on search button.\n",
    "    4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "    “Noida” and select location “Noida”.\n",
    "    5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "    6. Finally create a dataframe of the scraped data.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e1c77304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "19c16236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up ambitionbox.com website on automated chrome window\n",
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a2d2edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on job option in the given website\n",
    "click_on_job_option = driver.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[6]\")\n",
    "click_on_job_option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2a8369cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar\n",
    "search_field_designation = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input\")  #job search bar\n",
    "search_field_designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "69df9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on search button\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8599298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on location\n",
    "click_on_location = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]\")\n",
    "click_on_location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "880643ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for location\n",
    "search_field_location = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "search_field_location.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eb839634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on noida location\n",
    "click_on_noida = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label\")\n",
    "click_on_noida.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b9ce7dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list\n",
    "company_name_list = []\n",
    "ratings_list = []\n",
    "no_of_days_list = []\n",
    "\n",
    "#now lets extract all the tags having the company name, ratings and no of days ago job was posted\n",
    "company_name_tags = driver.find_elements_by_xpath(\"//a[@class='title noclick']\") #locating web element of company name\n",
    "for i in company_name_tags:               #iterating over web element of company name \n",
    "    company_name = i.text                  #fetching text from the web element\n",
    "    company_name_list.append(company_name)        #appending data(text) into the empty list\n",
    "        \n",
    "ratings_tags = driver.find_elements_by_xpath(\"//span[@class='body-small']\") #locating web element of ratings\n",
    "for i in ratings_tags:               #iterating over web element of ratings\n",
    "    ratings = i.text                  #fetching text from the web element\n",
    "    ratings_list.append(ratings)        #appending data(text) into the empty list\n",
    "        \n",
    "no_of_days_tags = driver.find_elements_by_xpath(\"//div[@class='other-info']/span[1]\") #locating web element of no of days\n",
    "for i in no_of_days_tags:               #iterating over web element of no of days\n",
    "    no_of_days = i.text                  #fetching text from the web element\n",
    "    no_of_days_list.append(no_of_days)        #appending data(text) into the empty list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "04d7ca9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>No of days ago when job was posted</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist- AI/ML- R&amp;D</td>\n",
       "      <td>12d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>24d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oracle HCM BI Technical Lead/Manager (People A...</td>\n",
       "      <td>10d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring For Data Scientist + Python/R+ Predicti...</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Immediate Joiners</td>\n",
       "      <td>19d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Machine Learning (5-14 yrs)</td>\n",
       "      <td>23d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist- Fresher Opening - Newgen Softw...</td>\n",
       "      <td>25d ago</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>10d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company Name  \\\n",
       "0                                     Data Scientist   \n",
       "1                         Data Scientist- AI/ML- R&D   \n",
       "2                                     Data Scientist   \n",
       "3  Oracle HCM BI Technical Lead/Manager (People A...   \n",
       "4  Hiring For Data Scientist + Python/R+ Predicti...   \n",
       "5                 Data Scientist - Immediate Joiners   \n",
       "6       Data Scientist - Machine Learning (5-14 yrs)   \n",
       "7  Data Scientist- Fresher Opening - Newgen Softw...   \n",
       "8                                     Data Scientist   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "  No of days ago when job was posted Ratings  \n",
       "0                             2d ago     4.3  \n",
       "1                            12d ago     3.9  \n",
       "2                            24d ago     4.0  \n",
       "3                            10d ago     3.9  \n",
       "4                           1mon ago     4.0  \n",
       "5                            19d ago     3.8  \n",
       "6                            23d ago     4.1  \n",
       "7                            25d ago     3.6  \n",
       "8                            10d ago     3.7  \n",
       "9                           1mon ago     4.2  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#makig a dataframe\n",
    "\n",
    "job_details = pd.DataFrame({})\n",
    "job_details['Company Name'] = company_name_list[0:10]\n",
    "job_details['No of days ago when job was posted'] =  no_of_days_list[0:10]\n",
    "job_details['Ratings'] = ratings_list[0:10]\n",
    "\n",
    "job_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "347ca96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to close automated chrome window\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01338c0",
   "metadata": {},
   "source": [
    "# Q10"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2af020e1",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "    1. First get the webpage https://www.ambitionbox.com/\n",
    "    2. Click on the salaries option as shown in the image.\n",
    "    3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "    then click on “Data Scientist”.\n",
    "    You have to scrape the data ticked in the above image.\n",
    "    4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "    salary, minimum salary, maximum salary, experience required.\n",
    "    5. Store the data in a dataframe.\n",
    "Note: All the steps required during scraping should be done through code only and not manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8a9b1490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\web driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a8f658bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening up ambitionbox.com website on automated chrome window\n",
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d020a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on salaries option in the given website\n",
    "click_on_salaries_option = driver.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[4]\")\n",
    "click_on_salaries_option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eb920e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar\n",
    "search_field_designation = driver.find_element_by_xpath(\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input\")  #job search bar\n",
    "search_field_designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6554f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on designation           \n",
    "designation = driver.find_element_by_xpath(\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div/p\") #locating web element of designation\n",
    "designation.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b0907a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list\n",
    "company_name_list = []\n",
    "total_salary_record = []\n",
    "average_salary_list = []\n",
    "minimum_salary_list = []\n",
    "maximum_salary_list = []\n",
    "required_experience = []\n",
    "\n",
    "#now lets extract all the tags having the company name, total salary record, average-minimum-maximum salary, experience required\n",
    "company_name_tags = driver.find_elements_by_xpath(\"//div[@class='name']/a\") #locating web element of company name\n",
    "for i in company_name_tags:               #iterating over web element of company name \n",
    "    company_name = i.text                  #fetching text from the web element\n",
    "    company_name_list.append(company_name)        #appending data(text) into the empty list\n",
    "        \n",
    "total_salary_tags = driver.find_elements_by_xpath(\"//div[@class='name']/span\") #locating web element of total salary record\n",
    "for i in total_salary_tags:               #iterating over web element of total salary record\n",
    "    total_salary = i.text.replace(\"based on\",\" \")                  #fetching text from the web element\n",
    "    total_salary_record.append(total_salary)        #appending data(text) into the empty list\n",
    "    \n",
    "average_salary_tags = driver.find_elements_by_xpath(\"//p[@class='averageCtc']\") #locating web element of average salary\n",
    "for i in average_salary_tags:               #iterating over web element of average salary\n",
    "    average_salary = i.text                  #fetching text from the web element\n",
    "    average_salary_list.append(average_salary)        #appending data(text) into the empty list\n",
    "    \n",
    "minimum_salary_tags = driver.find_elements_by_xpath(\"//div[@class='salary-values']/div[1]\") #locating web element of minimum salary\n",
    "for i in minimum_salary_tags:               #iterating over web element of minimum salary\n",
    "    minimum_salary = i.text                  #fetching text from the web element\n",
    "    minimum_salary_list.append(minimum_salary)        #appending data(text) into the empty list\n",
    "    \n",
    "maximum_salary_tags = driver.find_elements_by_xpath(\"//div[@class='salary-values']/div[2]\") #locating web element of maximum salary\n",
    "for i in maximum_salary_tags:               #iterating over web element of maximum salary\n",
    "    maximum_salary = i.text                  #fetching text from the web element\n",
    "    maximum_salary_list.append(maximum_salary)        #appending data(text) into the empty list\n",
    "        \n",
    "experience_tags = driver.find_elements_by_xpath(\"//div[@class='salaries sbold-list-header']\") #locating web element of required experience\n",
    "for i in experience_tags:               #iterating over web element of required experience\n",
    "    experience = i.text.split('\\n')[-1]                  #fetching text from the web element\n",
    "    required_experience.append(experience)        #appending data(text) into the empty list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ce798fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Total Salary Record</th>\n",
       "      <th>Average salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Experience required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>11 salaries</td>\n",
       "      <td>₹ 29.7L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "      <td>3 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>32 salaries</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reliance Jio</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹ 18.9L</td>\n",
       "      <td>₹ 5.6L</td>\n",
       "      <td>₹ 26.2L</td>\n",
       "      <td>4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹ 16.7L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>2 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>30 salaries</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>82 salaries</td>\n",
       "      <td>₹ 15.4L</td>\n",
       "      <td>₹ 9.7L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>47 salaries</td>\n",
       "      <td>₹ 14.8L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>55 salaries</td>\n",
       "      <td>₹ 13.9L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>13 salaries</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>4 yrs exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company Name Total Salary Record Average salary Minimum Salary  \\\n",
       "0                   Walmart         11 salaries        ₹ 29.7L        ₹ 25.0L   \n",
       "1                  Ab Inbev         32 salaries        ₹ 20.5L        ₹ 15.0L   \n",
       "2              Reliance Jio         10 salaries        ₹ 18.9L         ₹ 5.6L   \n",
       "3                        ZS         15 salaries        ₹ 16.7L        ₹ 11.0L   \n",
       "4                     Optum         30 salaries        ₹ 15.9L        ₹ 11.0L   \n",
       "5         Fractal Analytics         82 salaries        ₹ 15.4L         ₹ 9.7L   \n",
       "6           Tiger Analytics         47 salaries        ₹ 14.8L         ₹ 9.0L   \n",
       "7              UnitedHealth         55 salaries        ₹ 13.9L         ₹ 8.3L   \n",
       "8                   Verizon         14 salaries        ₹ 12.7L        ₹ 10.0L   \n",
       "9  Ganit Business Solutions         13 salaries        ₹ 12.4L         ₹ 8.5L   \n",
       "\n",
       "  Maximum Salary Experience required  \n",
       "0        ₹ 35.0L           3 yrs exp  \n",
       "1        ₹ 25.5L         3-4 yrs exp  \n",
       "2        ₹ 26.2L           4 yrs exp  \n",
       "3        ₹ 22.0L           2 yrs exp  \n",
       "4        ₹ 22.6L         3-4 yrs exp  \n",
       "5        ₹ 23.0L         2-4 yrs exp  \n",
       "6        ₹ 20.0L         2-4 yrs exp  \n",
       "7        ₹ 20.5L         2-4 yrs exp  \n",
       "8        ₹ 21.0L           4 yrs exp  \n",
       "9        ₹ 15.0L           4 yrs exp  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#makig a dataframe\n",
    "\n",
    "company_data = pd.DataFrame({})\n",
    "company_data['Company Name'] = company_name_list\n",
    "company_data['Total Salary Record'] =  total_salary_record\n",
    "company_data['Average salary'] = average_salary_list\n",
    "company_data['Minimum Salary'] = minimum_salary_list\n",
    "company_data['Maximum Salary'] = maximum_salary_list\n",
    "company_data['Experience required'] = required_experience\n",
    "\n",
    "company_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7c4097e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to close automated chrome window\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ff775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
